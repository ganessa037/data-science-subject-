{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPlDDFMH-vYk"
   },
   "source": [
    "# **Lab 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQj7TOt5-KZm"
   },
   "source": [
    "## Data Wrangling\n",
    "\n",
    "In this lab, you will learn various ways of manipulating (including some cleaning) data such as <font color=\"red\">merging data, duplicate removal, addressing missing data and transformation functions and mappings</font>. You will also go through two sample use cases using <font color=\"red\">car price data and minimum wage data</font>, and proceed to apply some of these techniques learned earlier. Finally, the processed data is turned into some simple descriptive analytics to churn out meaningful insights from visualizations.\n",
    "\n",
    "> **Credit note:** A portion of this lab was adapted from [this fantastic tutorial](https://lectures.quantecon.org/py/pandas_panel.html) from QuantEcon and `prakharrathi25`'s [Kaggle kernel](https://www.kaggle.com/prakharrathi25/data-wrangling/) on data wrangling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYUtvHIh3DVw"
   },
   "source": [
    "**Q1**: Replace the NaN data in `normalized-loss`, `peak-rpm`, `horsepower`, `bore`, `stroke` with their respective mean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yx1qnOSI-Kcf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cars' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# fill in here\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m cars[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized-losses\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak-rpm\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhorsepower\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbore\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstroke\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mcars\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized-losses\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak-rpm\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhorsepower\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbore\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstroke\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mto_numeric,errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(cars\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m      5\u001b[0m cars\u001b[38;5;241m.\u001b[39mfillna(cars\u001b[38;5;241m.\u001b[39mmean(),inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cars' is not defined"
     ]
    }
   ],
   "source": [
    "# fill in here\n",
    "\n",
    "cars[['normalized-losses','peak-rpm','horsepower','bore','stroke']] = \\\n",
    "cars[['normalized-losses','peak-rpm','horsepower','bore','stroke']].apply(pd.to_numeric,errors='coerce')\n",
    "print(cars.mean(numeric_only=True))\n",
    "cars.fillna(cars.mean(numeric_only=True),inplace=True)\n",
    "cars\n",
    "# note: Pandas cannot convert NaN to integer or floats, so to solve this\n",
    "# we need to convert the dataframe to numeric with errors=coerce option\n",
    "# after that, we can safely compute the mean, ignoring those "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUXRe8aK-Kc7"
   },
   "source": [
    "**Q2**: Drop all rows that do not have the price data. **Hint**: Use dropna(), specify which column to operate on with `subset` parameter\n",
    "\n",
    "<font color='red'>subset: array-like, optional\n",
    "Labels along other axis to consider, e.g. if you are dropping rows these would be a list of columns to include.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCSNmylM-Kc7"
   },
   "outputs": [],
   "source": [
    "# fill in here\n",
    "cars.dropna(subset=['price'],inplace=True)\n",
    "cars.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJI1HGFDKtvQ"
   },
   "source": [
    "A more common way of normalizing is to use both the minimum and maximum to adjust the values. This is called a min-max normalization.\n",
    "\n",
    "$$\\hat{x} = \\frac{x-x_{min}}{x_{max}-x_{min}}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YCLt2mR-Kdh"
   },
   "source": [
    "**Q3**: Compute the z-normalized value for `engine-size` and replace its values in `cars2` dataframe.\n",
    "\n",
    "$$\\hat{x} = \\frac{x-\\mu}{\\sigma}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gquYXFps-Kdi"
   },
   "outputs": [],
   "source": [
    "# fill in here\n",
    "#print(cars2.mean())\n",
    "#print(cars2.std())\n",
    "numeric_cols = cars2.select_dtypes(include=[np.number]).columns\n",
    "cars3 = cars.copy()\n",
    "cars3[numeric_cols] = (cars3[numeric_cols] - cars[numeric_cols].mean())/cars[numeric_cols].std()\n",
    "print(cars3[numeric_cols])\n",
    "\n",
    "# there are 2 other ways to do this: using pandas apply() with lambda function, use scipy.stats zscore function\n",
    "from scipy.stats import zscore\n",
    "numeric_cols = cars2.select_dtypes(include=[np.number]).columns\n",
    "print(cars2[numeric_cols].apply(zscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dv1n5Lg9-KfZ"
   },
   "source": [
    "**Q4**: Figure out how to aggregate over columns, giving the average minimum wage for all countries over the time period. (Hint: the `axis` by default is aggregating over rows).This is what we call a *time series* graph, data over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ml2hxPz3-KfZ"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "wage_f.mean(axis=1).sort_values(ascending=False).plot(kind='line', title=\"Average minimum wage 2006 - 2016\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab04_sol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
